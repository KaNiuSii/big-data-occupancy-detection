services:
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"      # dla innych kontenerÃ³w i hosta
    environment:
      # KRaft: jeden wÄ™zeÅ‚ jako broker + controller
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"

      # SÅ‚uchacze (broker + controller)
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"

      # ðŸ’¥ TO JEST KRYTYCZNE â€“ bez tego masz TwÃ³j bÅ‚Ä…d
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qg"

      # Single node: faktory replikacji na 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"

      # Å»eby topiki tworzyÅ‚y siÄ™ same przy pierwszym uÅ¼yciu
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

  spark:
    image: apache/spark:latest
    container_name: spark
    depends_on:
      - kafka
    # Spark master UI port â€“ ALE w apache/spark nie ma domyÅ›lnego mastera,
    # wiÄ™c i tak bÄ™dziemy odpalaÄ‡ spark-submit z master=local[*]
    ports:
      - "8080:8080"
    volumes:
      - ./ml:/opt/app
    working_dir: /opt/app
    command: ["/bin/bash", "-c", "tail -f /dev/null"]
