services:
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    ports:
      - "9092:9092"     # internal listener (dla kontenerÃ³w)
      - "29092:29092"   # external listener (dla hosta Windows)
    environment:
      # KRaft: jeden wÄ™zeÅ‚ jako broker + controller
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"

      # === LISTENERS ===
      KAFKA_LISTENERS: "PLAINTEXT_INTERNAL://0.0.0.0:9092,PLAINTEXT_EXTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093"

      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT_INTERNAL://kafka:9092,PLAINTEXT_EXTERNAL://localhost:29092"

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT"

      # ðŸ”§ TO DODALIÅšMY:
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT_INTERNAL"

      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"

      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qg"

      # Single node: faktory replikacji na 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"

      # Å»eby topiki tworzyÅ‚y siÄ™ same przy pierwszym uÅ¼yciu
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"


  spark:
    image: apache/spark:latest
    container_name: spark
    user: "0:0"
    depends_on:
      - kafka
    # Spark master UI port â€“ ALE w apache/spark nie ma domyÅ›lnego mastera,
    # wiÄ™c i tak bÄ™dziemy odpalaÄ‡ spark-submit z master=local[*]
    ports:
      - "8080:8080"
    volumes:
      - ./:/opt/app
    working_dir: /opt/app
    command: ["/bin/bash", "-c", "tail -f /dev/null"]
